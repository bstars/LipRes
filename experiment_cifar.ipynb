{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "\n",
    "from ori_layers import SandwichFc, SandwichConv, SandwichLin, LinearNormalized, MultiMargin, LipResFC, LipResConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device='cpu'\n",
    "batch_size = 64\n",
    "w = 1 # can be 1, 2, 4, indicating the network size\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "mean = [0.4914, 0.4822, 0.4465]\n",
    "std  = [0.2470, 0.2435, 0.2616]\n",
    "normalize = transforms.Normalize(mean=mean, std=std)\n",
    "hue = 0.02\n",
    "saturation = (.3, 2.)\n",
    "brightness = 0.1\n",
    "contrast = (.5, 2.)\n",
    "\n",
    "transforms_list = [transforms.RandomCrop(32, padding=4, padding_mode='reflect'),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(\n",
    "            brightness=brightness, contrast=contrast,\n",
    "            saturation=saturation, hue=hue),\n",
    "        transforms.ToTensor(),\n",
    "        normalize]\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms.Compose(transforms_list))\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms.Compose([transforms.ToTensor(),normalize]))\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-1.9895) tensor(2.1265)\n",
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for x, y in testloader:\n",
    "    print(x.min(), x.max())\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "def train_net(model):\n",
    "    epochs = 100\n",
    "    lr = 1e-2\n",
    "\n",
    "    criterion = MultiMargin()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr,  weight_decay=0)\n",
    "    lr_schedule = lambda t: np.interp([t], [0, epochs*2//5, epochs*4//5, epochs], [0, lr, lr/20.0, 0])[0]\n",
    "\n",
    "    for epoch in range(100):  # loop over the dataset multiple times\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "\n",
    "            lr = lr_schedule(epoch + (i+1)/len(trainloader))\n",
    "            opt.param_groups[0].update(lr=lr)\n",
    "\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)#.view(-1, 32 * 32 * 3)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            opt.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            if i % 10 == 0:    # print every 2000 mini-batches\n",
    "                print(epoch, i, loss.item())\n",
    "\n",
    "    print('Finished Training')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0.4470723867416382\n",
      "0 10 0.4483972489833832\n",
      "0 20 0.4494003355503082\n",
      "0 30 0.44101962447166443\n",
      "0 40 0.4514889717102051\n",
      "0 50 0.447468101978302\n",
      "0 60 0.44915860891342163\n",
      "0 70 0.44953662157058716\n",
      "0 80 0.45385026931762695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x127809280>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/wangjiarui/miniconda3/envs/ml/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1479, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/Users/wangjiarui/miniconda3/envs/ml/lib/python3.8/site-packages/torch/utils/data/dataloader.py\", line 1443, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/Users/wangjiarui/miniconda3/envs/ml/lib/python3.8/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/Users/wangjiarui/miniconda3/envs/ml/lib/python3.8/multiprocessing/popen_fork.py\", line 44, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "  File \"/Users/wangjiarui/miniconda3/envs/ml/lib/python3.8/multiprocessing/connection.py\", line 931, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/Users/wangjiarui/miniconda3/envs/ml/lib/python3.8/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 3>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, l \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(lips):\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;66;03m# net = nn.Sequential(\u001B[39;00m\n\u001B[1;32m      5\u001B[0m     \u001B[38;5;66;03m#     SandwichConv(3, 32 * w, 3, scale=np.sqrt(l)),\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     12\u001B[0m     \u001B[38;5;66;03m#     SandwichLin(512 * w,10, scale=np.sqrt(l))\u001B[39;00m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;66;03m# ).to(device)\u001B[39;00m\n\u001B[1;32m     15\u001B[0m     net \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mSequential(\n\u001B[1;32m     16\u001B[0m         LipResConv(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m32\u001B[39m \u001B[38;5;241m*\u001B[39m w, \u001B[38;5;241m3\u001B[39m, strided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, L \u001B[38;5;241m=\u001B[39m lips_layer[i]),\n\u001B[1;32m     17\u001B[0m         LipResConv(\u001B[38;5;241m32\u001B[39m \u001B[38;5;241m*\u001B[39m w, \u001B[38;5;241m32\u001B[39m \u001B[38;5;241m*\u001B[39m w, \u001B[38;5;241m3\u001B[39m, strided\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, L \u001B[38;5;241m=\u001B[39m lips_layer[i]),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     23\u001B[0m         LipResFC(\u001B[38;5;241m512\u001B[39m \u001B[38;5;241m*\u001B[39m w,\u001B[38;5;241m10\u001B[39m, L \u001B[38;5;241m=\u001B[39m lips_layer[i])\n\u001B[1;32m     24\u001B[0m     )\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m---> 25\u001B[0m     \u001B[43mtrain_net\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnet\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     26\u001B[0m     torch\u001B[38;5;241m.\u001B[39msave(net\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./lip_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00ml\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[0;32mIn [6]\u001B[0m, in \u001B[0;36mtrain_net\u001B[0;34m(model)\u001B[0m\n\u001B[1;32m     26\u001B[0m outputs \u001B[38;5;241m=\u001B[39m net(inputs)\n\u001B[1;32m     27\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, labels)\n\u001B[0;32m---> 28\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m opt\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m i \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m10\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:    \u001B[38;5;66;03m# print every 2000 mini-batches\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/ml/lib/python3.8/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "lips = np.array([1, 10, 100])\n",
    "lips_layer = np.exp(np.log(lips) / 7)\n",
    "for i, l in enumerate(lips):\n",
    "    # net = nn.Sequential(\n",
    "    #     SandwichConv(3, 32 * w, 3, scale=np.sqrt(l)),\n",
    "    #     SandwichConv(32 * w, 32 * w, 3, stride=2),\n",
    "    #     SandwichConv(32 * w, 64 * w, 3),\n",
    "    #     SandwichConv(64 * w, 64 * w, 3, stride=2),\n",
    "    #     nn.Flatten(),\n",
    "    #     SandwichFc(64 * 8 * 8 * w, 512 * w),\n",
    "    #     SandwichFc(512 * w, 512 * w),\n",
    "    #     SandwichLin(512 * w,10, scale=np.sqrt(l))\n",
    "    # ).to(device)\n",
    "\n",
    "    net = nn.Sequential(\n",
    "        LipResConv(3, 32 * w, 3, strided=False, L = lips_layer[i]),\n",
    "        LipResConv(32 * w, 32 * w, 3, strided=True, L = lips_layer[i]),\n",
    "        LipResConv(32 * w, 64 * w, 3, strided=False, L = lips_layer[i]),\n",
    "        LipResConv(64 * w, 64 * w, 3, strided=True, L = lips_layer[i]),\n",
    "        nn.Flatten(),\n",
    "        LipResFC(64 * 8 * 8 * w, 512 * w, L = lips_layer[i]),\n",
    "        LipResFC(512 * w, 512 * w, L = lips_layer[i]),\n",
    "        LipResFC(512 * w,10, L = lips_layer[i])\n",
    "    ).to(device)\n",
    "    train_net(net)\n",
    "    torch.save(net.state_dict(), f'./lip_{l}.pth')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 0.709375\n",
      "10 0.76875\n",
      "100 0.7984375\n"
     ]
    }
   ],
   "source": [
    "lips = np.array([1, 10, 100])\n",
    "lips_layer = np.exp(np.log(lips) / 7)\n",
    "act = nn.ReLU\n",
    "for i, l in enumerate(lips):\n",
    "    net = nn.Sequential(\n",
    "        LipResConv(3, 32 * w, 3, strided=False, L = lips_layer[i]),\n",
    "        LipResConv(32 * w, 32 * w, 3, strided=True, L = lips_layer[i]),\n",
    "        LipResConv(32 * w, 64 * w, 3, strided=False, L = lips_layer[i]),\n",
    "        LipResConv(64 * w, 64 * w, 3, strided=True, L = lips_layer[i]),\n",
    "        nn.Flatten(),\n",
    "        LipResFC(64 * 8 * 8 * w, 512 * w, L = lips_layer[i]),\n",
    "        LipResFC(512 * w, 512 * w, L = lips_layer[i]),\n",
    "        LipResFC(512 * w,10, L = lips_layer[i])\n",
    "    ).to(device)\n",
    "\n",
    "    net.load_state_dict(torch.load(f'./ckpts/lip_{l}_small.pth', map_location=torch.device('cpu')))\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    iter = 0\n",
    "    for x, y in testloader:\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = net(x)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += y.size(0)\n",
    "            correct += (predicted == y).sum().item()\n",
    "\n",
    "        iter += 1\n",
    "        if iter % 10 == 0:\n",
    "            break\n",
    "\n",
    "    print(l, correct / total)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ml",
   "language": "python",
   "display_name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
